{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MikolajWasowski/neural-network-course/blob/master/02_basics/03_loss_functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpksqwHQTyN0"
      },
      "source": [
        "* @author: krakowiakpawel9@gmail.com  \n",
        "* @site: e-smartdata.org"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gjFu2l9IMsj"
      },
      "source": [
        "### Funkcje Straty - Loss Function:\n",
        "1. [Entropia rozkładu prawdopodobieństwa](#a0)\n",
        "2. [Binarna entropia krzyżowa - Binary Crossentropy](#a1)\n",
        "3. [Kategoryczna entropia krzyżowa - Categorical Crossentropy](#a0)\n",
        "\n",
        "#### <a name='a0'></a> 1. Entropia rozkładu prawdopodobieństwa\n",
        "$$Entropia = - \\sum_{i}p_{i} * log(p_{i})$$\n",
        "Gdzie $p_{i}$ to prawdopodobieństwo zajścia $i$-tego zdarzenia. Entropia charakteryzuje mozliwośc oddawania informacji przez żródło. Inaczej jest to miara nieokreśloności/niepewności. Średnie zdziwienie (wartość oczekiwana zdziwienia)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVlLr1EBD3nj",
        "outputId": "605b0a70-caf4-4dfd-a6c3-f4369915285a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.15.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyxtFjeeGECa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e5defbf-dfec-420a-86e4-2bb78281ad55"
      },
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(precision=6, suppress=True)\n",
        "\n",
        "def entropy(labels, base=None):\n",
        "    from math import log, e\n",
        "    n_labels = len(labels)\n",
        "\n",
        "    if n_labels <= 1:\n",
        "        return 0\n",
        "\n",
        "    value, counts = np.unique(labels, return_counts=True)\n",
        "    probs = counts / n_labels\n",
        "    n_classes = np.count_nonzero(probs)\n",
        "\n",
        "    if n_classes <= 1:\n",
        "        return 0\n",
        "\n",
        "    ent = 0.\n",
        "\n",
        "    base = e if base is None else base\n",
        "    for i in probs:\n",
        "        ent -= i * log(i, base)\n",
        "    return ent\n",
        "\n",
        "\n",
        "labels = [1,3,5,2,3,5,3,2,1,3,4,5]\n",
        "entropy(labels)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.5171063970610277"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_7m4M8MZkHp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d4c1b05-d59c-4c4c-cf89-00278c4867bc"
      },
      "source": [
        "labels = [3, 3, 3, 3, 3, 3, 3]\n",
        "entropy(labels)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyRgL5ybaV7N"
      },
      "source": [
        "#### <a name='a1'></a> 2. Binarna entropia krzyżowa - Binary Crossentropy\n",
        "$$Binary\\ CrossEntropy = - \\frac{1}{N}\\sum_{i=1}^{N}(y_{i}*log(p(y_{i})) + (1-y_{i}) * log(1-p(y_{i}))$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXA1CKEAbs6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17b96e22-7497-4aa9-9369-8606bee1004b"
      },
      "source": [
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "\n",
        "y_true = np.array([1, 0, 1, 1, 0, 1], dtype='float')\n",
        "y_pred = np.array([0, 0, 1, 1, 0, 1], dtype='float')\n",
        "\n",
        "binary_crossentropy(y_true, y_pred)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float64, numpy=2.5708247450663957>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EK-uYzfca0tG"
      },
      "source": [
        "#### <a name='a2'></a> 3. Kategoryczna entropia krzyżowa - Categorical Crossentropy\n",
        "$$Categorical\\ CrossEntropy= - \\sum_{i}y_{i} * log(p(y_{i})) $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXCV2LIlanLc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfc05adb-0f8d-4a63-ea24-77dd9be27415"
      },
      "source": [
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "\n",
        "y_true = np.array([1, 0, 1, 1, 2, 0, 1, 1, 2], dtype='float')\n",
        "y_pred = np.array([0, 0, 1, 1, 2, 0, 1, 2, 2], dtype='float')\n",
        "\n",
        "categorical_crossentropy(y_true, y_pred)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float64, numpy=30.23015636684835>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16rmIAP2hwN3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22f87530-72aa-4f93-8446-c2668835df0e"
      },
      "source": [
        "y_true = np.array([0, 0, 1, 1, 2, 0, 1, 1, 2], dtype='float')\n",
        "y_pred = np.array([0, 1, 1, 2, 0, 1, 1, 2, 1], dtype='float')\n",
        "\n",
        "categorical_crossentropy(y_true, y_pred)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float64, numpy=44.03324440481406>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}